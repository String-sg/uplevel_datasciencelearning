{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In Part I, we downloaded data from OULAD and previewed the data mostly. \n",
    "\n",
    "On top of that, the CSVs on their own are not entirely useful - you'll need to use your skills to combine the various CSVs together so you can get a final DataFrame that you can use to predict student dropouts. \n",
    "\n",
    "In this notebook we will:\n",
    "1. Import the pandas library\n",
    "2. Load CSVs as DataFrames for inspection \n",
    "3. Combine the DataFrames in a meaningful way\n",
    "4. Export the DataFrames as CSV\n",
    "\n",
    "### Step 1: Import library\n",
    "You'll just need:\n",
    "1. pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import the library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "Here, we will prepare and merge the data in meaningful ways.\n",
    "\n",
    "### Step 2: Read student Assessment CSV as DataFrame\n",
    "We'll start with reading 'studentAssessment.csv' first. studentAssessment contains the scores of the students who took a particular assessment in a course.\n",
    "\n",
    "However, we can't use it as it is because we need to summarize the students' performance across different tests first before we can combine it with other datasets. \n",
    "\n",
    "![studentAssessmentExtraction.png](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectLearningAnalytics/studentAssessmentExtraction.png)\n",
    "\n",
    "In this part, we will steadily transform studentAssessment into a simpler form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Read studentAssessment.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Get a groupby based on id_student, and get the mean, max, and min\n",
    "Firstly, we will perform a groupby operation and group them based on 'id_student'. After that, get the mean, max, and min of the score.\n",
    "\n",
    "![groupbyScore.png](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectLearningAnalytics/groupbyScore.png)\n",
    "\n",
    "<strong>Hint: the documentation for groupby is useful - https://pandas.pydata.org/pandas-docs/version/0.22.0/generated/pandas.core.groupby.DataFrameGroupBy.agg.html</strong>\n",
    "\n",
    "<strong>Hint 2: another good reading for groupby - https://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Groupby id_student to get the score's mean, max, min"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Reset index and rename the columns\n",
    "When performing groupby operations with agg methods, you inevitably end up with 2-level column names, i.e. (score, mean) instead of mean.\n",
    "\n",
    "Since we need our columns to be simple before combining it with other DataFrames, next you will: \n",
    "1. reset the index \n",
    "2. renaming the columns to 'id_student', 'mean', 'max', 'min'\n",
    "\n",
    "![studentScoreResetIndex.png](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectLearningAnalytics/studentScoreResetIndex.png)\n",
    "\n",
    "Make sure your resultant DataFrame looks like the one in Step 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4a: Reset index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4b: Rename columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Read studentVle CSV into a DataFrame\n",
    "Next up, let's take a look at the studentVle CSV, where it contains students' activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 5: Read studentVle CSV into a DataFrame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Groupby studentVle and get sum of clicks\n",
    "There are 10M+ interactions recorded in studentVle, but what we truly need is to answer this question:\n",
    "<blockquote>What is the sum of clicks for a student, in each code presentation in each code module?</blockquote>\n",
    "As such, we need to perform a groupby operation based on:\n",
    "\n",
    "1. code_module\n",
    "2. code_presentation\n",
    "3. id_student\n",
    "\n",
    "in a list, and you aggregate them via a sum for 'sum_click' column.\n",
    "\n",
    "You should see something like this:\n",
    "\n",
    "![groupbySumClick.png](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectLearningAnalytics/groupbySumClick.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Perform a groupby so that you get the sum for sum_clicks per student in each code_presentation and code_module "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Reset the DataFrame\n",
    "After you're done with the groupby operation, you can then reset the index. \n",
    "\n",
    "Resetting the index helps bring the multi-level index back to normal and simple index which makes it easier for DataFrame merging later on.\n",
    "\n",
    "![studentVleResetIndex.png](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectLearningAnalytics/studentVleResetIndex.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Reset the index of the groupby stundentvle DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Read studentInfo CSV into a DataFrame\n",
    "Time to load the star of the show - the studentInfo CSV. \n",
    "\n",
    "We will be using this CSV in our later Parts as well so we will clean and combine this with other data such as the one that you just got from Step 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 8: Load studentInfo.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Count the number of missing data in the DataFrame\n",
    "Let's see if there are missing datapoints in the DataFrame. \n",
    "\n",
    "Count the sum of null values in the DataFrame. \n",
    "\n",
    "<strong>Hint: Google \"how to count the NaN values in a column in pandas DataFrame\"</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Assess how many missing values per column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Replace missing values in imd_band with 'Missing'\n",
    "What we can do is replace the missing values in imd_band with the string 'Missing'.\n",
    "\n",
    "<strong>Hint: Google \"replace na in pandas column\"</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10a: Replace the NaN in 'imd_band' column with 'Missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10b: Check the number of missing values in the DataFrame to check if you have filled the NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Get unique number of id_student in DataFrame\n",
    "Wait a minute - if you noticed, there are 32,593 rows in studentInfo, but only 23,369 rows from the DataFrame that you got from Step 4. \n",
    "\n",
    "What's happening here - let's find out by investigating id_student column in studentInfo.\n",
    "\n",
    "More specifically, let's get the unique number of values in id_student.\n",
    "\n",
    "<strong>Hint: Google \"get number of unique values in column pandas\"</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Get number of unique values in id_student "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Drop duplicates from the id_student column\n",
    "Looks like there are duplicates in the id_student column. For simplicity, we will remove duplicates from the column, based only on the 'id_student' column. \n",
    "\n",
    "Sanity check - after you remove your duplicates, you should have:\n",
    "1. 28,785 rows\n",
    "2. 12 columns\n",
    "\n",
    "<strong>Hint: Google \"drop duplicate based on column pandas\"</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 12: Drop duplicates from id_student column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging DataFrames\n",
    "Now that we've prepared our DataFrames for analysis, we can now merge these DataFrames. Here's the order that will merge our data in:\n",
    "1. studentInfo + studentVle (groupby) = studentInfo_Vle\n",
    "2. studentInfo_Vle + studentScores (groupby) = studentInfo_Vle_Scores\n",
    "\n",
    "### Step 13: Left merge studentInfo (Step 12) and studentVle (Step 7)\n",
    "You will <strong><font color = 'red'>merge</font></strong> the DataFrames that you got from Steps 12 and 7, based <strong><font color = 'red'>on</font></strong> the three columns:\n",
    "1. code_module\n",
    "2. code_presentations\n",
    "3. id_student\n",
    "\n",
    "![FirstMergeDataFrame.png](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectLearningAnalytics/FirstMergeDataFrame.png)\n",
    "\n",
    "Sanity check after merging - you will have:\n",
    "1. 28,785 rows\n",
    "2. 13 columns\n",
    "\n",
    "If you're not getting the right numbers, you should check the Hints out. \n",
    "\n",
    "<strong>Hint: make sure it's a <font color = 'red'>left</font> merge</strong>\n",
    "\n",
    "<strong>Hint 2: Merge! How? Left!</strong>\n",
    "\n",
    "<strong>Hint 3: make sure it's in the correct DataFrame order when you're merging</strong>\n",
    "\n",
    "<strong>Hint 4: Google \"merging two dataframes in python\"</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Step 13: Do a left merge between Step 12 DataFrame and Step 7 DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14: Count missing values in columns\n",
    "Repeat Step 9 and count the number of missing values in your columns after merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Count missing values in columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 15: Fill missing values in 'sum_click' with 0\n",
    "If you did your merging correctly, turns out that there are missing values in 'sum_clicked', i.e. there were students who did not click anything at all in the VLE.\n",
    "\n",
    "Let's replace NaN in that 'sum_click' column with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 15a: Replace NaN with 0 in 'sum_click'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 15b: Check the total number of missing values in all columns again"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 16: Left merge the merged DataFrame (Step 15) and studentScore (Step 4)\n",
    "Similar to Step 13, do a <strong><font color = 'red'>left merge</font></strong> using our Step 15 DataFrame with the Step 4 studentScore <strong><font color = 'red'>on</font></strong>: \n",
    "1. 'id_content'\n",
    "\n",
    "This is what you'll see:\n",
    "\n",
    "![SecondMergeDataFrame.png](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectLearningAnalytics/SecondMergeDataFrame.png)\n",
    "\n",
    "Sanity check:\n",
    "1. 28,785 rows\n",
    "2. 16 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Step 16: Perform a left merge on your DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 17: Fill missing data in mean/max/min column with median\n",
    "As you can see, there were NaN that appeared in all three columns. \n",
    "\n",
    "What we'll do is fill the NaN in each of the columns with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 17a: Fill missing data in mean/max/min columns with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 17b: Check for missing column data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 18: Export the combined DataFrame as a CSV\n",
    "Now that we've done our loading, cleaning, and merging, it's time to export this merged DataFrame as CSV for subsequent Parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 18: Export the combined DataFrame as a CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
